!pip install --upgrade openai
!pip install gTTS
from google.colab import userdata
from openai import OpenAI
client = OpenAI(
  api_key= userdata.get('api_key'),
)
from gtts import gTTS #Import Google Text to Speech
from IPython.display import Audio #Import Audio method from IPython's Display Class
def getUserInput():
  some_text = input('How can I help you ? ')
  return some_text
def askGPT():
    completion = client.chat.completions.create(
      model="gpt-3.5-turbo",
      messages=[
        {"role": "system", "content": "You are a general purpose chatbot"},
        {"role": "user", "content": getUserInput() }
      ]
    )
    response_from_chatGPT = completion.choices[0].message.content
    return response_from_chatGPT
def speakNow(content):
  tts = gTTS(content) #Provide the string to convert to speech
  tts.save('1.wav') #save the string converted to speech as a .wav file
  sound_file = '1.wav'
  Audio(sound_file, autoplay=True)
wanna_ask_more = 'y'

while wanna_ask_more == 'y':
  ans = askGPT()
  speakNow(ans)
  sound_file = '1.wav'
  Audio(sound_file, autoplay=True)
  print('-------------- ')
  wanna_ask_more= input("Wanna ask more questions ?? y/n - ")
!pip install speechrecognition
!pip install pyttsx3
!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg
!pip install pyaudio
import speech_recognition as sr
import pyttsx3

# Initialize the recognizer
r = sr.Recognizer()

# Function to convert text to
# speech
def SpeakText(command):

    # Initialize the engine
    engine = pyttsx3.init()
    engine.say(command)
    engine.runAndWait()
# all imports
from io import BytesIO
from base64 import b64decode
from google.colab import output
from IPython.display import Javascript

RECORD = """
const sleep  = time => new Promise(resolve => setTimeout(resolve, time))
const b2text = blob => new Promise(resolve => {
  const reader = new FileReader()
  reader.onloadend = e => resolve(e.srcElement.result)
  reader.readAsDataURL(blob)
})
var record = time => new Promise(async resolve => {
  stream = await navigator.mediaDevices.getUserMedia({ audio: true })
  recorder = new MediaRecorder(stream)
  chunks = []
  recorder.ondataavailable = e => chunks.push(e.data)
  recorder.start()
  await sleep(time)
  recorder.onstop = async ()=>{
    blob = new Blob(chunks)
    text = await b2text(blob)
    resolve(text)
  }
  recorder.stop()
})
"""

def record(sec=3):
  print("Speak Now...")
  display(Javascript(RECORD))
  sec += 1
  s = output.eval_js('record(%d)' % (sec*1000))
  print("Done Recording !")
  b = b64decode(s.split(',')[1])
  return b #byte stream
voice = record()